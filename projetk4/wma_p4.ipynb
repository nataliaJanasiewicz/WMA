{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55D61hm6DHV5"
      },
      "outputs": [],
      "source": [
        "PATH = os.getcwd()\n",
        "PATH_DATA = os.path.join(PATH, 'data')\n",
        "PATH_DATA_CATEGORIES = os.path.join(PATH_DATA, 'categories')\n",
        "PATH_DATA_MODEL = os.path.join(PATH_DATA, 'model_h5')\n",
        "PATH_DATA_CATEGORIES_DICTIONARY = os.path.join(PATH_DATA, 'categories.dict')\n",
        "\n",
        "IMAGE_SIZE = (32, 32)\n",
        "TRAIN_SIZE = 0.9\n",
        "RANDOM_STATE = 420\n",
        "\n",
        "KERNEL_SIZE1 = 32\n",
        "KERNEL_SIZE2 = 64\n",
        "STRIDES = (3, 3)\n",
        "PADDING = 'same'\n",
        "ACTIVATION1 = 'relu'\n",
        "ACTIVATION2 = 'softmax'\n",
        "POOL_SIZE = (2, 2)\n",
        "DROPOUT = 0.25\n",
        "DENSE = 512\n",
        "\n",
        "LR = 0.0001\n",
        "DECAY = 1e-6\n",
        "\n",
        "LOSS = 'categorical_crossentropy'\n",
        "METRICS = ['accuracy']\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu5WXwG6DC_f"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from PIL import Image, ImageFilter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
        "from keras import models\n",
        "from keras.engine.functional import Functional\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
        "from tensorflow.keras.engine.functional import Functional\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs9xbMepDAQx",
        "outputId": "f3f2da08-ed12-4703-ecb2-90c52676d73e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] Augmenting images in /content/data/categories/ksiazka\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] Augmenting images in /content/data/categories/kubek\n",
            "[+] Augmenting images in /content/data/categories/klawiatura\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "#przejscie przez elementy w PATH_DATA_CATEGORIES\n",
        "for dir_name in os.listdir(PATH_DATA_CATEGORIES):\n",
        "  #sprawdzenie czy nie zaczyna sie od . -> potrzeba bo .DS_store na mac\n",
        "    if not dir_name.startswith('.'):\n",
        "        dir_path = os.path.join(PATH_DATA_CATEGORIES, dir_name)\n",
        "        print('[+] Augmenting images in {}'.format(dir_path))\n",
        "        for image_name in os.listdir(dir_path):\n",
        "            image_path = os.path.join(dir_path, image_name)\n",
        "            img, ext = os.path.splitext(image_path)\n",
        "            shape = np.array(Image.open(image_path).convert('RGB')).shape #kszta≈Çt obrazu\n",
        "\n",
        "            #zmiana do rgb bo jpeg\n",
        "            Image.open(image_path).convert('RGB').crop((15, 45, shape[1] - 45, shape[1] - 15)).save(\n",
        "                '{}_CROPPED{}'.format(img, ext))\n",
        "            for rot in range(15, 360, 15):\n",
        "                Image.open(image_path).convert('RGB').rotate(rot).save('{}_R{}{}'.format(img, rot, ext))\n",
        "                Image.open(image_path).convert('RGB').transpose(Image.FLIP_LEFT_RIGHT).save('{}_LR{}'.format(img, ext))\n",
        "                Image.open(image_path).convert('RGB').transpose(Image.FLIP_TOP_BOTTOM).save('{}_TB{}'.format(img, ext))\n",
        "                Image.open(image_path).convert('RGB').filter(ImageFilter.GaussianBlur(3)).save('{}_BLUR{}'.format(img, ext))\n",
        "                Image.open(image_path).convert('RGB').filter(ImageFilter.SMOOTH).save('{}_SMOOTH{}'.format(img, ext))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm0obmd8DQd_",
        "outputId": "2cf47109-137b-4037-f20f-a4b8b6109f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] Reading images in /content/data/categories/ksiazka\n",
            "[+] Reading images in /content/data/categories/kubek\n",
            "[+] Reading images in /content/data/categories/klawiatura\n",
            "[+] Saving categories dictionary to /content/data/categories.dict\n",
            "Model\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 13, 13, 64)        36928     \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               1180160   \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,247,267\n",
            "Trainable params: 1,247,267\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[+] Compiling and fitting model\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 16.4197 - accuracy: 0.3846 - val_loss: 16.9142 - val_accuracy: 0.6667\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 1s 592ms/step - loss: 28.5524 - accuracy: 0.3846 - val_loss: 8.3809 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 18.9895 - accuracy: 0.3846 - val_loss: 13.6837 - val_accuracy: 0.6667\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 1s 543ms/step - loss: 21.3460 - accuracy: 0.4231 - val_loss: 7.0769 - val_accuracy: 0.3333\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 1s 586ms/step - loss: 8.2255 - accuracy: 0.5000 - val_loss: 4.7157 - val_accuracy: 0.6667\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 6.5966 - accuracy: 0.5000 - val_loss: 4.7121 - val_accuracy: 0.3333\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 453ms/step - loss: 13.4938 - accuracy: 0.3846 - val_loss: 8.0298 - val_accuracy: 0.3333\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 15.9790 - accuracy: 0.4231 - val_loss: 3.7661 - val_accuracy: 0.3333\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 14.4253 - accuracy: 0.4615 - val_loss: 6.5742 - val_accuracy: 0.3333\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 12.3274 - accuracy: 0.3462 - val_loss: 2.9170 - val_accuracy: 0.3333\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 6.4447 - accuracy: 0.3846 - val_loss: 2.7427 - val_accuracy: 0.6667\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 7.4496 - accuracy: 0.4615 - val_loss: 1.4862 - val_accuracy: 0.6667\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 5.6043 - accuracy: 0.5769 - val_loss: 4.8284 - val_accuracy: 0.6667\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 7.5514 - accuracy: 0.3846 - val_loss: 2.6219 - val_accuracy: 0.6667\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 5.8652 - accuracy: 0.5000 - val_loss: 3.6238 - val_accuracy: 0.6667\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 5.4944 - accuracy: 0.3077 - val_loss: 2.6015 - val_accuracy: 0.6667\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 3.7205 - accuracy: 0.5385 - val_loss: 3.0649 - val_accuracy: 0.3333\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 6.2761 - accuracy: 0.3846 - val_loss: 4.1926 - val_accuracy: 0.6667\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 6.1722 - accuracy: 0.5000 - val_loss: 2.6954 - val_accuracy: 0.3333\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 4.2458 - accuracy: 0.6154 - val_loss: 2.7917 - val_accuracy: 0.6667\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 8.0343 - accuracy: 0.3077 - val_loss: 2.9655 - val_accuracy: 0.6667\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 6.9433 - accuracy: 0.2692 - val_loss: 1.2247 - val_accuracy: 0.6667\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 2.9646 - accuracy: 0.6923 - val_loss: 2.6533 - val_accuracy: 0.3333\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 4.2105 - accuracy: 0.5000 - val_loss: 2.2853 - val_accuracy: 0.6667\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 4.2176 - accuracy: 0.5385 - val_loss: 2.3746 - val_accuracy: 0.6667\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 3.6727 - accuracy: 0.5769 - val_loss: 0.5562 - val_accuracy: 0.6667\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 4.3123 - accuracy: 0.5000 - val_loss: 2.3518 - val_accuracy: 0.6667\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 3.6659 - accuracy: 0.5385 - val_loss: 1.2000 - val_accuracy: 0.6667\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 4.1867 - accuracy: 0.5385 - val_loss: 2.8118 - val_accuracy: 0.6667\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 5.2187 - accuracy: 0.5000 - val_loss: 1.2586 - val_accuracy: 0.6667\n",
            "[+] Saving model to /content/data/model_h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 43ms/step - loss: 1.2586 - accuracy: 0.6667\n",
            "[+] Loss: 1.2586236000061035, Acc: 0.6666666865348816\n"
          ]
        }
      ],
      "source": [
        "categories_dictionary = dict() #mapowanie indeks√≥w kategorii na nazwy kategorii.\n",
        "images_list = list()\n",
        "categories_list = list()\n",
        "i = 0\n",
        "for dir_name in os.listdir(PATH_DATA_CATEGORIES):\n",
        "  if not dir_name.startswith('.'):\n",
        "                categories_dictionary.update({i: dir_name})\n",
        "                dir_path = os.path.join(PATH_DATA_CATEGORIES, dir_name)\n",
        "                print('[+] Reading images in {}'.format(dir_path))\n",
        "                for image_name in os.listdir(dir_path):\n",
        "                    image_path = os.path.join(dir_path, image_name)\n",
        "                    image = Image.open(image_path)\n",
        "                    image = image.resize(IMAGE_SIZE, resample=Image.BILINEAR)\n",
        "                    image_array = np.array(image)\n",
        "                    if image_array.shape != (32, 32, 3):\n",
        "                        continue  # Pomijaj obrazy, kt√≥re nie majƒÖ oczekiwanego rozmiaru\n",
        "                    images_list.append(image_array)\n",
        "                    categories_list.append(i)\n",
        "                i += 1\n",
        "\n",
        "print('[+] Saving categories dictionary to {}'.format(PATH_DATA_CATEGORIES_DICTIONARY))\n",
        "with open(PATH_DATA_CATEGORIES_DICTIONARY, 'wb') as dictionary_file: pickle.dump(categories_dictionary, dictionary_file)\n",
        "\n",
        "images_array = np.asarray(images_list)\n",
        "categories_array = np.asarray(categories_list)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images_array, categories_array,\n",
        "                                                            train_size=TRAIN_SIZE,\n",
        "                                                            random_state=RANDOM_STATE)\n",
        "\n",
        "y_train = to_categorical(y_train, len(categories_dictionary.keys()))\n",
        "y_test = to_categorical(y_test, len(categories_dictionary.keys()))\n",
        "\n",
        "#model i warstwy konwolucyjne\n",
        "print('Model')\n",
        "model = Sequential()\n",
        "model.add(\n",
        "            Conv2D(KERNEL_SIZE1, STRIDES, padding=PADDING,\n",
        "                   input_shape=images_array.shape[1:]))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(Conv2D(KERNEL_SIZE1, STRIDES))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
        "model.add(Dropout(DROPOUT))\n",
        "\n",
        "model.add(Conv2D(KERNEL_SIZE2, STRIDES, padding=PADDING))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(Conv2D(KERNEL_SIZE2, STRIDES))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
        "model.add(Dropout(DROPOUT))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(DENSE))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(len(categories_dictionary.keys())))\n",
        "model.add(Activation(ACTIVATION2))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print('[+] Compiling and fitting model')\n",
        "\n",
        "#learning_rate_decay nie jest dostƒôpny w optymalizatorze RMSprop w Keras.\n",
        "optimizer = optimizers.RMSprop(lr=LR, decay=DECAY)\n",
        "\n",
        "model.compile(loss=LOSS, optimizer=optimizer, metrics=METRICS)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "                  validation_data=(x_test, y_test), shuffle=True)\n",
        "\n",
        "print('[+] Saving model to {}'.format(PATH_DATA_MODEL))\n",
        "model.save(PATH_DATA_MODEL)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('[+] Loss: {}, Acc: {}'.format(test_loss, test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Pl0bkJK1FX_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0314a877-165d-416a-9bd3-fd0940d874bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Reading images in /content/data/categories/ksiazka\n",
            "[+] Reading images in /content/data/categories/kubek\n",
            "[+] Reading images in /content/data/categories/klawiatura\n",
            "[+] Saving categories dictionary to /content/data/categories.dict\n",
            "Model\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " activation_20 (Activation)  (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 13, 13, 64)        36928     \n",
            "                                                                 \n",
            " activation_21 (Activation)  (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               1180160   \n",
            "                                                                 \n",
            " activation_22 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            " activation_23 (Activation)  (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,247,267\n",
            "Trainable params: 1,247,267\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[+] Compiling and fitting model\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 7s 227ms/step - loss: 14.5978 - accuracy: 0.3657 - val_loss: 1.7545 - val_accuracy: 0.5057\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 4s 159ms/step - loss: 5.8184 - accuracy: 0.3606 - val_loss: 1.3534 - val_accuracy: 0.4943\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 2.9619 - accuracy: 0.4463 - val_loss: 1.0905 - val_accuracy: 0.5287\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 5s 194ms/step - loss: 1.8357 - accuracy: 0.5038 - val_loss: 0.9306 - val_accuracy: 0.5632\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 4s 161ms/step - loss: 1.3044 - accuracy: 0.5435 - val_loss: 0.7615 - val_accuracy: 0.6667\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 5s 195ms/step - loss: 1.0551 - accuracy: 0.5934 - val_loss: 0.6249 - val_accuracy: 0.7011\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 5s 180ms/step - loss: 0.8688 - accuracy: 0.6522 - val_loss: 0.5456 - val_accuracy: 0.7931\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 4s 163ms/step - loss: 0.7359 - accuracy: 0.6867 - val_loss: 0.5920 - val_accuracy: 0.7586\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 5s 214ms/step - loss: 0.6601 - accuracy: 0.7136 - val_loss: 0.4328 - val_accuracy: 0.8736\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 4s 164ms/step - loss: 0.5464 - accuracy: 0.7801 - val_loss: 0.5208 - val_accuracy: 0.7931\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 4s 161ms/step - loss: 0.4717 - accuracy: 0.8043 - val_loss: 0.4486 - val_accuracy: 0.8276\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 5s 215ms/step - loss: 0.4078 - accuracy: 0.8338 - val_loss: 0.3655 - val_accuracy: 0.8851\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 0.3828 - accuracy: 0.8529 - val_loss: 0.3480 - val_accuracy: 0.8736\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 4s 156ms/step - loss: 0.3163 - accuracy: 0.8721 - val_loss: 0.2686 - val_accuracy: 0.9195\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 5s 216ms/step - loss: 0.2888 - accuracy: 0.8964 - val_loss: 1.0007 - val_accuracy: 0.6552\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 0.2856 - accuracy: 0.9054 - val_loss: 0.3516 - val_accuracy: 0.8736\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 4s 161ms/step - loss: 0.2030 - accuracy: 0.9271 - val_loss: 0.2782 - val_accuracy: 0.9195\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 5s 216ms/step - loss: 0.2454 - accuracy: 0.9041 - val_loss: 0.2233 - val_accuracy: 0.9310\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 4s 164ms/step - loss: 0.1785 - accuracy: 0.9373 - val_loss: 0.9119 - val_accuracy: 0.6437\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 4s 164ms/step - loss: 0.1729 - accuracy: 0.9425 - val_loss: 0.2426 - val_accuracy: 0.9195\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 5s 216ms/step - loss: 0.2064 - accuracy: 0.9182 - val_loss: 0.2784 - val_accuracy: 0.9080\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 4s 160ms/step - loss: 0.1415 - accuracy: 0.9463 - val_loss: 0.4317 - val_accuracy: 0.8621\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 4s 167ms/step - loss: 0.1272 - accuracy: 0.9514 - val_loss: 0.3596 - val_accuracy: 0.8736\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 5s 210ms/step - loss: 0.1143 - accuracy: 0.9604 - val_loss: 0.2962 - val_accuracy: 0.8736\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 4s 156ms/step - loss: 0.1582 - accuracy: 0.9501 - val_loss: 0.2537 - val_accuracy: 0.9310\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 4s 176ms/step - loss: 0.0985 - accuracy: 0.9668 - val_loss: 0.1779 - val_accuracy: 0.9540\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 5s 193ms/step - loss: 0.1392 - accuracy: 0.9565 - val_loss: 0.1857 - val_accuracy: 0.9195\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 4s 159ms/step - loss: 0.1088 - accuracy: 0.9565 - val_loss: 0.1430 - val_accuracy: 0.9540\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 5s 189ms/step - loss: 0.0675 - accuracy: 0.9795 - val_loss: 0.1403 - val_accuracy: 0.9655\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.1228 - val_accuracy: 0.9655\n",
            "[+] Saving model to /content/data/model_h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 35ms/step - loss: 0.1228 - accuracy: 0.9655\n",
            "[+] Loss: 0.12276821583509445, Acc: 0.9655172228813171\n"
          ]
        }
      ],
      "source": [
        "categories_dictionary = dict()\n",
        "images_list = list()\n",
        "categories_list = list()\n",
        "i = 0\n",
        "for dir_name in os.listdir(PATH_DATA_CATEGORIES):\n",
        "  if not dir_name.startswith('.'):\n",
        "                categories_dictionary.update({i: dir_name})\n",
        "                dir_path = os.path.join(PATH_DATA_CATEGORIES, dir_name)\n",
        "                print('[+] Reading images in {}'.format(dir_path))\n",
        "                for image_name in os.listdir(dir_path):\n",
        "                    image_path = os.path.join(dir_path, image_name)\n",
        "                    image = Image.open(image_path)\n",
        "                    image = image.resize(IMAGE_SIZE, resample=Image.BILINEAR)\n",
        "                    image_array = np.array(image)\n",
        "                    if image_array.shape != (32, 32, 3):\n",
        "                        continue  # Pomijaj obrazy, kt√≥re nie majƒÖ oczekiwanego rozmiaru\n",
        "                    images_list.append(image_array)\n",
        "                    categories_list.append(i)\n",
        "                i += 1\n",
        "\n",
        "print('[+] Saving categories dictionary to {}'.format(PATH_DATA_CATEGORIES_DICTIONARY))\n",
        "with open(PATH_DATA_CATEGORIES_DICTIONARY, 'wb') as dictionary_file: pickle.dump(categories_dictionary, dictionary_file)\n",
        "\n",
        "images_array = np.asarray(images_list)\n",
        "categories_array = np.asarray(categories_list)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(images_array, categories_array,\n",
        "                                                            train_size=TRAIN_SIZE,\n",
        "                                                            random_state=RANDOM_STATE)\n",
        "\n",
        "y_train = to_categorical(y_train, len(categories_dictionary.keys()))\n",
        "y_test = to_categorical(y_test, len(categories_dictionary.keys()))\n",
        "\n",
        "print('Model')\n",
        "model = Sequential()\n",
        "model.add(\n",
        "            Conv2D(KERNEL_SIZE1, STRIDES, padding=PADDING,\n",
        "                   input_shape=images_array.shape[1:]))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(Conv2D(KERNEL_SIZE1, STRIDES))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
        "model.add(Dropout(DROPOUT))\n",
        "\n",
        "model.add(Conv2D(KERNEL_SIZE2, STRIDES, padding=PADDING))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(Conv2D(KERNEL_SIZE2, STRIDES))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(MaxPooling2D(pool_size=POOL_SIZE))\n",
        "model.add(Dropout(DROPOUT))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(DENSE))\n",
        "model.add(Activation(ACTIVATION1))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(len(categories_dictionary.keys())))\n",
        "model.add(Activation(ACTIVATION2))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print('[+] Compiling and fitting model')\n",
        "\n",
        "optimizer = optimizers.RMSprop(lr=LR, decay=DECAY)\n",
        "\n",
        "#optimizer = optimizers.RMSprop(lr=LR, decay=DECAY)\n",
        "\n",
        "model.compile(loss=LOSS, optimizer=optimizer, metrics=METRICS)\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "                  validation_data=(x_test, y_test), shuffle=True)\n",
        "\n",
        "print('[+] Saving model to {}'.format(PATH_DATA_MODEL))\n",
        "model.save(PATH_DATA_MODEL)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('[+] Loss: {}, Acc: {}'.format(test_loss, test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E79pTniMH3Ta",
        "outputId": "dae30a81-bbbe-4ab8-e290-97043f502c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder zosta≈Ç usuniƒôty wraz z zawarto≈õciƒÖ.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# ≈öcie≈ºka do folderu, kt√≥ry chcesz usunƒÖƒá\n",
        "folder_path = \"/content/data/categories/ksiazka\"\n",
        "\n",
        "# Usuniƒôcie zawarto≈õci folderu\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "        os.unlink(file_path)\n",
        "    elif os.path.isdir(file_path):\n",
        "        shutil.rmtree(file_path)\n",
        "\n",
        "# Usuniƒôcie samego folderu\n",
        "os.rmdir(folder_path)\n",
        "\n",
        "# Potwierdzenie usuniƒôcia folderu\n",
        "print(\"Folder zosta≈Ç usuniƒôty wraz z zawarto≈õciƒÖ.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}